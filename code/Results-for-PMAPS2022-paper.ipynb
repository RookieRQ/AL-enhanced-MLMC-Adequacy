{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel Monte Carlo with Surrogate Models for Resource Adequacy Assessment\n",
    "Author: Ensieh Sharifnia and Simon Tindemans, Delft University of Technology, 2021-2022.\n",
    "Released under the MIT license.\n",
    "\n",
    "This notebook generates results that are similar\\* to those in the paper *Multilevel Monte Carlo with Surrogate Models for\n",
    "Resource Adequacy Assessment* by Ensieh Sharifnia and Simon Tindemans, to be presented at the PMAPS 2022 conference. \n",
    "\n",
    "A preprint of the paper is available here: https://arxiv.org/abs/2203.03437. If you use (portions of) this code, please reference the published paper.\n",
    "\n",
    "\\*: Similarity only due to dependence on execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import MCCoordinator\n",
    "import StorageSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# initialise logging facility\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "    # initialise global logging facility\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def storage_system(train_size, **kwargs):\n",
    "    \"\"\"\n",
    "    Instantiate StorageSystem object using GB system data\n",
    "\n",
    "    :param wind_power: assumed wind power capacity (in MW)\n",
    "    :param kwargs: additional arguments to be supplied to the StorageSystem constructor\n",
    "    :return: StorageSystem object\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    data = pd.read_csv('../data/UKdata/20161213_uk_wind_solar_demand_temperature.csv',\n",
    "                       parse_dates=['UTC Time', 'Local Time'], infer_datetime_format=True, dayfirst=True, index_col=0)\n",
    "\n",
    "    demand_data = data['demand_net'].dropna()['2006':'2015']\n",
    "    wind_data = 10000 * data['wind_merra1'].dropna()\n",
    "\n",
    "    demand_samples = {yeardata[0]: yeardata[1].values[:8760] for yeardata in\n",
    "                      demand_data.groupby(demand_data.index.year)}\n",
    "    wind_samples = {yeardata[0]: yeardata[1].values[:8760] for yeardata in wind_data.groupby(wind_data.index.year)}\n",
    "\n",
    "    dataframe = pd.read_csv('../data/UKdata/battery_data.csv')\n",
    "    store_power_list=3*dataframe['Power (MW)'][0:27]\n",
    "    store_energy_list=3*dataframe['Energy (MWh)'][0:27]\n",
    "\n",
    "    return StorageSampler.StorageSystem(demand_samples=demand_samples, \n",
    "                                        wind_samples=wind_samples, \n",
    "                                        store_power_list=store_power_list,\n",
    "                                        store_energy_list=store_energy_list,\n",
    "                                         train_size=train_size,\n",
    "                                        **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose):\n",
    "    '''\n",
    "    Run MLMC simulation\n",
    "    Parameters:\n",
    "        samples: int\n",
    "            initial number of samples in each level for sigma estimation.\n",
    "        n_run: int\n",
    "            number of runs for MLMC simulation.\n",
    "        time_seconds: int\n",
    "            duration for each run of MLMC simulation.\n",
    "        train_size: int\n",
    "            number of training samples for training surrogate models\n",
    "        ml_hierarchy: {'OptimalNStore', 'GreedyNStore', 'AIGreedyNStore', 'Greedy1Store', 'AvgStore', 'NoStore', 'AIModel'}\n",
    "            set of models for MLMC structure.\n",
    "        use_joblib: bool\n",
    "            if Ture: use all cores, otherwise run on a single core.\n",
    "        Verbose: bool\n",
    "            if Ture: print with details, otherwise: print summery of results\n",
    "    '''\n",
    "    mcc = MCCoordinator.MCCoordinator(factory=system, \n",
    "                                    ml_hierarchy=ml_hierarchy, \n",
    "                                    use_expectations=True, \n",
    "                                    use_joblib=use_joblib, joblib_n_jobs=-1, joblib_batch_size=5)\n",
    "    mcc.explore(n_samples=samples)\n",
    "    for i in range(n_run):\n",
    "        mcc.run_recommended(time_seconds=time_seconds, verbose=verbose, optimization_target='EENS')\n",
    "    mcc.verbose_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MLMC for different structures\n",
    "used in Table I & Fig 1 & Fig 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters for run\n",
    "samples = 500\n",
    "n_run = 50\n",
    "time_seconds = 500\n",
    "train_size = 5000\n",
    "use_joblib = False\n",
    "verbose = False\n",
    "system = storage_system(train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estimator: MC , Architecture: Exact\n",
    "ml_hierarchy = ['OptimalNStore']\n",
    "run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator: TS20 base , Architecture: Exact|Avg\n",
    "ml_hierarchy = ['OptimalNStore', 'AvgStore']\n",
    "run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator: Surr , Architecture: Exact|HGB+SVR\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel']\n",
    "run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator: TS20 full , Architecture: Exact | Gre | Avg\n",
    "ml_hierarchy = ml_hierarchy = ['OptimalNStore', 'GreedyNStore', 'AvgStore']\n",
    "run_MLMC(samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator: Surr+base , Architecture: Exact | HGB+SVR | Avg\n",
    "ml_hierarchy = ['OptimalNStore', 'AIModel', 'AvgStore']\n",
    "run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator:Hybrid+base, Architecture:  Exact | HGB+Gre | Avg\n",
    "ml_hierarchy = ['OptimalNStore', 'AIGreedyNStore', 'AvgStore']\n",
    "run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator:Full, Architecture:  Exact | HGB+Gre | HGB+SVR | Avg\n",
    "ml_hierarchy = ['OptimalNStore', 'AIGreedyNStore', 'AIModel', 'AvgStore']\n",
    "run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE II\n",
    "Effects of training sample size on surrogate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scientific_notation(risk_value, std_error):\n",
    "        '''\n",
    "        providing scientific notation for risk value along with standard deviation\n",
    "        Parameters:\n",
    "            risk_value: float\n",
    "            std_error: float\n",
    "        Returns:\n",
    "            string of scientific notation\n",
    "        '''\n",
    "        EFFECTIVE_ZERO = 1e-7\n",
    "        if std_error < EFFECTIVE_ZERO and risk_value< EFFECTIVE_ZERO:\n",
    "            return '{}({})'.format(int(risk_value), int(std_error))\n",
    "        std_error_e = \"{:.5e}\".format(std_error)\n",
    "        risk_e = \"{:.10e}\".format(risk_value)\n",
    "        std_error_power = int(std_error_e[std_error_e.find('e')+1:])\n",
    "        risk_power = int(risk_e[risk_e.find('e')+1:])\n",
    "        precision = risk_power - std_error_power\n",
    "        \n",
    "        std_e = int(np.round(float(std_error_e[0:std_error_e.find('e')])))\n",
    "        if (std_e < 3):\n",
    "            precision +=1\n",
    "            std_error_e = \"{:.2e}\".format(std_error)\n",
    "            std_e = int(np.round(float(std_error_e[0:std_error_e.find('e')])*10))\n",
    "        f = \"{:.\"+str(precision)+\"e}\"\n",
    "        risk_e = f.format(risk_value)\n",
    "        \n",
    "        if risk_power>3 or risk_power<-3 :\n",
    "            return '{}({}).10^{}'.format(risk_e[0:risk_e.find('e')], std_e, risk_power)\n",
    "        elif risk_power<4 and std_error_power>=0:\n",
    "            if std_error_power==0 and int(np.round(std_error))<3 :\n",
    "                f = \"{:.1e}\"\n",
    "                risk_e = float(risk_e)\n",
    "            else:\n",
    "                std_e = int(np.round(std_error))\n",
    "                risk_e = int(np.round(risk_value))\n",
    "            return \"{}({})\".format(risk_e, std_e)\n",
    "        else:\n",
    "            return \"{}({})\".format(float(risk_e), std_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters for run\n",
    "train_size = [500, 1000, 5000]\n",
    "n_run = 5\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "import MachineLearning\n",
    "print(\"_______________________________________________________________________\")\n",
    "print (\"Surrogate model      Train size         Average RMSE      RMSE unit\")\n",
    "print(\"_______________________________________________________________________\")\n",
    "lol_arr = np.zeros(n_run)\n",
    "ens_arr = np.zeros(n_run)\n",
    "ML = MachineLearning.MachineLearning(train_size= 5, use_real_lol=True)\n",
    "X_test = ML.load_data(\"../data/AIdata/daily_margin_test.csv\")\n",
    "ens_test = ML.load_data(\"../data/AIdata/ens_test.csv\")\n",
    "lol_test = ML.load_data(\"../data/AIdata/lol_test.csv\")\n",
    "for st in train_size:\n",
    "    for i in range(n_run):\n",
    "        ML = MachineLearning.MachineLearning(train_size= st, use_real_lol=True)\n",
    "        X_test = ML.load_data(\"../data/AIdata/daily_margin_test.csv\")\n",
    "        lol_hat, ens_hat = ML.predict(X_test)\n",
    "        lol_arr[i] = mean_squared_error( lol_test, lol_hat, squared=False)\n",
    "        ens_arr[i] = mean_squared_error( ens_test, ens_hat, squared=False)\n",
    "\n",
    "    lole = np.mean(lol_arr)\n",
    "    lol_stdr = np.std(lol_arr, axis=0, ddof = 1)/ np.sqrt(lol_arr.shape[0])\n",
    "    print(f\"HGBRT                  {st}                {scientific_notation(lole, lol_stdr)}        (h/y)\")\n",
    "    eens = np.mean(ens_arr)\n",
    "    eens_stdr = np.std(ens_arr, axis=0, ddof = 1)/ np.sqrt(ens_arr.shape[0])\n",
    "    print(f\"SVR                    {st}                {scientific_notation(eens, eens_stdr)}           (MWh/y)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE III\n",
    "Effect of surrogate model accuracy on MLMC performance\n",
    "NOTE: for TS20 full, and training size = 5000, we used table I data.\n",
    "Therefore, we just need to compute Hybrid+base and Full estimator with training sample =[500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters for run\n",
    "samples = 500\n",
    "n_run = 50\n",
    "time_seconds = 500\n",
    "train_size = 5000\n",
    "use_joblib = False\n",
    "verbose = False\n",
    "train_size = [500, 1000]\n",
    "for st in train_size: \n",
    "    system = storage_system(train_size=st)\n",
    "#     surrogate accuracy:\n",
    "    X_test = system.AI_model.load_data(\"../data/AIdata/daily_margin_test.csv\")\n",
    "    ens_test = system.AI_model.load_data(\"../data/AIdata/ens_test.csv\")\n",
    "    lol_test = system.AI_model.load_data(\"../data/AIdata/lol_test.csv\")\n",
    "    lol_hat, ens_hat = system.AI_model.predict(X_test)\n",
    "    print(f\"HGBRT RMSE (h/y): {mean_squared_error( lol_test, lol_hat, squared=False):.4f}\")\n",
    "    print(f\"SVR RMSE (MWh/y): {mean_squared_error( ens_test, ens_hat, squared=False):.4f}\")\n",
    "    # Estimator:Full, Architecture:  Exact | HGB+Gre | HGB+SVR | Avg\n",
    "    ml_hierarchy = ['OptimalNStore', 'AIGreedyNStore', 'AIModel', 'AvgStore']\n",
    "    run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)\n",
    "\n",
    "    # Estimator:Hybrid+base, Architecture:  Exact | HGB+Gre | Avg\n",
    "    ml_hierarchy = ['OptimalNStore', 'AIGreedyNStore', 'AvgStore']\n",
    "    run_MLMC(system, samples, n_run, time_seconds, train_size, ml_hierarchy, use_joblib, verbose)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
